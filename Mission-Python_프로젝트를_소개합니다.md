## **AI 시대, 신뢰할 수 있는 코딩 교육을 위한 자동 평가 시스템 안내서**

---

### **목차**

1.  **서론: 새로운 시대의 정직한 평가를 향한 여정**
2.  **시스템 둘러보기: 우리의 약속을 지키는 자동화 생태계**
3.  **학생의 경험: 문제 해결에만 집중하는 시험 환경**
4.  **교수의 시선: 투명하고 효율적인 평가의 모든 과정**
5.  **평가의 심장, '인스펙터': 14명의 전문가가 내리는 종합 진단**
6.  **점수를 넘어 성장으로: 데이터 기반의 맞춤형 피드백**
7.  **시작하기: 시스템 설치 및 운영 가이드**
8.  **결론: 평가는 '심판'이 아닌 '코칭'이 되어야 합니다**
9.  **부록: 관련 프로젝트 GitHub 저장소**
10. **참고문헌**

---

### **1. 서론: 새로운 시대의 정직한 평가를 향한 여정**

교실 안, 한 교수가 완벽에 가까운 학생의 코드를 보며 깊은 고민에 빠집니다. "이 놀라운 코드는 과연 이 학생의 머릿속에서 나온 고뇌의 산물일까, 아니면 인공지능(AI)에게 질문하여 단 몇 초 만에 얻어낸 결과물일까?" 생성형 AI가 우리 곁으로 다가온 오늘날, 이는 교육 현장의 모든 이들이 마주한 새로운 시대의 질문입니다.

GitHub Copilot, ChatGPT와 같은 AI 도구들은 놀라운 생산성을 선물했지만, 동시에 우리는 수십 년간 이어져 온 '결과물 중심 평가'의 신뢰도가 흔들리는 현실과 마주하게 되었습니다. 최종 코드만으로는 더 이상 학생의 진정한 실력과 노력의 과정을 가늠하기 어려워졌습니다.

이러한 도전을 극복하고자 우리는 평가의 관점을 바꾸기로 했습니다. 최종 결과물이라는 '종착역'이 아닌, 그곳에 도달하기까지의 **'여정'** 그 자체에 주목하기로 한 것입니다. 학생이 코드를 작성하며 남기는 디지털 발자취, 즉 **'과정'** 속에는 AI가 흉내 낼 수 없는 고뇌의 흔적, 시행착오, 그리고 성장의 이야기가 고스란히 담겨있습니다.

이 안내서는 바로 그 '과정'의 가치를 공정하게 평가하고, AI 시대에 흔들리지 않는 신뢰의 기준을 세우기 위해 탄생한 종합 자동화 프레임워크에 대한 이야기입니다. 우리의 목표는 감시가 아닌, 학생들의 진정한 노력을 투명하게 인정하고 성장을 돕는 건강한 교육 생태계를 만드는 것입니다.

### **2. 시스템 둘러보기: 우리의 약속을 지키는 자동화 생태계**

이 프레임워크는 하나의 프로그램이 아닌, 각자의 전문 분야를 가진 여러 도구들이 유기적으로 협력하는 하나의 생태계와 같습니다. 마치 잘 짜인 오케스트라처럼, 각 도구(연주자)들이 자신의 역할을 완벽히 수행할 때, 공정하고 신뢰도 높은 평가라는 아름다운 하모니가 완성됩니다.

이 오케스트라의 주요 연주자들을 소개합니다.

| 구분 | 컴포넌트 (연주자) | 역할 (비유: 오케스트라에서의 역할) |
| :--- | :--- | :--- |
| **학생 환경** | 🐍 [**`mission-python`**][p1] | **성실한 악보 기록원**: 학생(작곡가)이 만드는 모든 멜로디(코드)와 작업 과정(작곡 시간, 수정 내역)을 한순간도 놓치지 않고 비밀 악보에 자동으로 기록합니다. |
| **평가자 환경** | 🚀 [**`Orchestrator`**][p2] | **지휘자**: 평가가 시작되면 모든 연주자에게 정확한 타이밍에 연주를 지시하고, 전체 평가 과정이 순조롭게 진행되도록 총괄합니다. |
| | 🔐 [**`mission-decoder`**][p3] | **비밀 악보 해독가**: 학생이 제출한 암호화된 비밀 악보를 지휘자만 가진 특별한 열쇠로 풀어내어, 평가단이 읽을 수 있도록 준비합니다. |
| | 🦊 [**`mission-restore`**][p4] | **음악 고고학자**: 해독된 악보의 모든 수정 기록을 따라가며, 학생이 최종적으로 완성한 멜로디(최종 코드)를 완벽하게 복원해냅니다. |
| | 🔎 [**`duplicate_finder`**][p5] | **필적 감정 전문가**: 혹시 여러 학생이 똑같은 악보를 제출하지는 않았는지, 공연 시작 전 모든 악보를 꼼꼼하게 비교하여 위조 여부를 가려냅니다. |
| | 🧠 [**`Inspector`**][p6] | **14인의 전문 심사위원단**: 복원된 악보와 전체 작곡 과정을 보며, 학생의 창의성, 노력, 테크닉(개발 과정의 질)을 다각도로 심층 분석하여 최종 점수를 매깁니다. |

이처럼 학생이 자신의 음악(코드)을 만드는 과정에만 집중하면, 나머지 복잡한 평가 과정은 이 자동화된 오케스트라가 투명하고 일관되게 수행합니다.

### **3. 학생의 경험: 문제 해결에만 집중하는 시험 환경**

학생 여러분에게 이 시스템은 복잡한 평가 도구가 아닌, 여러분의 노력을 온전히 담아주는 '디지털 스케치북'이자 '블랙박스 비행 기록 장치'가 될 것입니다. 시험 과정은 놀랍도록 간단합니다.

**여러분의 시험 여정은 이렇게 진행됩니다:**
1.  **스케치북 펼치기:** 제공된 `mission-python` 프로젝트 폴더를 열고, `poetry install` 명령어로 필요한 물감(라이브러리)을 준비합니다.
2.  **작품 구상 및 스케치:** 여러분은 오직 `src/mission_python/main.py`라는 단 하나의 하얀 도화지에만 집중하여 문제에 대한 해답(코드)을 그려나가면 됩니다.
3.  **과정 기록하기:** 그림을 그리다가 중간 결과를 확인하고 싶을 때, 터미널에 다음 마법의 주문을 외워주세요.
    ```bash
    poetry run python src/mission_python/main.py
    ```
    이 주문을 외울 때마다, 여러분이 지금까지 그린 모든 선과 색칠(코드 변경 이력)이 **자동으로 암호화되어 안전하게 기록됩니다.** 마치 스케치북의 매 페이지가 여러분만 아는 비밀 일기처럼 저장되는 것과 같습니다.
4.  **스케치북 제출:** 시험이 끝나면, 복잡하게 정리할 필요 없이 이 '디지털 스케치북'(`mission-python` 폴더)을 통째로 제출하면 됩니다.

**기억해주세요:** 이 시스템은 여러분이 얼마나 꾸준히, 점진적으로 고민하며 문제를 해결했는지를 중요하게 생각합니다. 마지막 순간에 마법처럼 그림을 완성하는 것보다, 차근차근 스케치하고 색을 입혀나가는 성실한 과정이 더 높은 평가를 받습니다. AI를 좋은 참고서처럼 활용하는 것은 좋지만, 책의 내용을 그대로 베껴 그리는 것은 여러분의 성장 과정을 보여주지 못하기에 좋은 평가를 받기 어렵습니다. 여러분의 진정한 노력이 온전히 기록되고 인정받는 환경이니, 안심하고 여러분의 실력을 마음껏 펼쳐주세요.

### **4. 교수의 시선: 투명하고 효율적인 평가의 모든 과정**

교수님과 조교님께 이 프레임워크는, 공정한 평가를 향한 고민을 덜어드리는 든든한 '자동 평가 조교'가 되어 드립니다. 학생들의 제출물을 받은 후, 단 한 번의 명령으로 수십, 수백 명의 평가를 일관되고 투명하게 처리할 수 있습니다.

**평가는 다음과 같은 자동화된 검증 절차를 거칩니다:**
1.  **전체 제출물 비교 (표절 사전 차단):** 가장 먼저 `duplicate_finder`가 모든 학생의 암호화된 로그 파일을 비교합니다. 마치 시험 시작 전 신분증을 대조하듯, 다른 학생의 결과물을 그대로 제출한 경우를 즉시 식별합니다.

2.  **암호 해독 및 기록 확인:** 다음으로, `mission-decoder`가 교수님만 가진 개인키로 각 학생의 '잠긴 일기장'(암호화된 로그)을 엽니다. 이 안에는 학생의 모든 개발 과정과 시험을 치른 환경 정보가 담겨있습니다.

3.  **다각적 진실성 검증:**
    *   **누가, 어디서 시험을 보았는가? (대리 시험 방지):** `signature` 기록을 분석하여 학생의 IP 주소, 위치 정보 등을 확인합니다. 이를 통해 허가된 장소에서 본인이 직접 시험을 치렀는지를 검증할 수 있습니다.
    *   **스스로의 힘으로 풀었는가? (답안 복사 방지):** `mission-restore`가 학생의 '개발 일기'를 처음부터 끝까지 따라가며 최종 결과물을 복원합니다. 그리고 이 복원된 결과물을 학생이 제출한 최종 답안과 비교합니다. 두 결과물이 일치한다면, 학생이 제출한 답안은 그 학생의 노력의 과정에서 비롯된 진정한 결과물임을 시스템이 증명해주는 셈입니다.

4.  **개발 과정 심층 분석:** 위의 모든 검증을 통과한 '진실한' 결과물에 대해, `Inspector`라는 전문가 심사위원단이 개발 과정의 질적 수준을 깊이 있게 평가합니다. 이 과정은 다음 섹션에서 자세히 다룹니다.

이 모든 절차를 통해, 교수님은 "학생이 정직하게 시험을 치렀는가?"라는 질문에 대한 객관적인 데이터를 확보하고, 평가의 공정성과 신뢰도를 굳건히 지킬 수 있습니다.

### **5. 평가의 심장, '인스펙터': 14명의 전문가가 내리는 종합 진단**

학생의 개발 과정이 '진실하다'는 것이 확인되면, 이제 그 과정이 '얼마나 우수한가'를 평가해야 합니다. 이 중요한 임무는 프레임워크의 두뇌 역할을 하는 `Inspector`가 수행합니다.

`Inspector`는 마치 의료 분야의 '다학제 진료'와 같습니다. 한 명의 의사가 아닌, 각기 다른 분야의 전문의 14명이 환자(학생의 개발 로그)의 상태를 함께 진단하여 최종 소견을 내리는 방식입니다. 이 '전문가 위원회'는 다음과 같은 지능적인 방식으로 평가를 수행합니다.

1.  **초진 (개발 패턴 자동 분류):** 먼저 학생의 개발 기록을 전체적으로 훑어보며 거시적인 패턴을 진단합니다. "매우 꾸준하고 이상적인 개발자", "마감 시간에 임박하여 급하게 개발하는 벼락치기 유형", "AI의 결과물을 그대로 붙여넣은 것으로 강력히 의심되는 유형" 등 5가지 주요 패턴으로 분류합니다.

2.  **협진 (동적 가중치 적용):** 진단된 패턴에 따라, 해당 분야의 최고 전문가들의 의견에 더 큰 비중을 둡니다. 예를 들어, '벼락치기' 패턴이 발견되면, 시간 관리의 효율성을 분석하는 전문가들의 목소리에 더 귀를 기울입니다. 'AI 답안 복붙'이 의심되면, 명백한 규칙 위반을 탐지하는 전문가들의 의견을 최우선으로 고려합니다.

3.  **최종 소견 (집단 지성을 통한 판정):** 이렇게 각 전문가의 의견을 상황에 맞게 종합하여 최종 점수를 산출합니다. 이러한 '동적 앙상블' 방식 덕분에, 단일 모델이 가질 수 있는 편견이나 실수를 방지하고, 학생의 개발 과정을 훨씬 더 입체적이고 공정하게 평가할 수 있습니다. 한 명의 심사위원이 아닌, 14명의 전문가로 구성된 위원회가 내리는 종합적인 판단이기에, 학생과 교수 모두 그 결과를 신뢰할 수 있습니다.

### **6. 점수를 넘어 성장으로: 데이터 기반의 맞춤형 피드백**

이 프레임워크의 진정한 가치는 채점에 그치지 않고, 학생 개개인의 성장을 돕는 구체적인 피드백을 제공하는 데 있습니다. `Inspector`는 분석 결과를 바탕으로 모든 학생에게 개인화된 **HTML 상세 보고서**를 제공합니다.

이 보고서는 단순한 성적표가 아닌, 학생을 위한 '성장 가이드북'입니다.
-   **나의 개발 스타일 진단:** "당신의 개발 패턴은 '이상적인 작업자' 유형입니다"와 같이, 시스템이 분석한 학생의 개발 스타일을 알려줍니다.
-   **투명한 점수 공개:** 14명의 전문가가 각각 몇 점을 주었고, 왜 그렇게 평가했는지에 대한 핵심 의견을 투명하게 공개하여 점수에 대한 궁금증을 해소해줍니다.
-   **구체적인 증거 제시:** "개발 시작 5분 만에 전체 코드의 80%가 추가됨"과 같이, 점수에 영향을 미친 긍정적, 부정적 행동을 실제 데이터에 기반하여 명확히 보여줍니다.
-   **성장을 위한 맞춤형 제안:** 분석된 문제점을 개선하기 위해 "AI가 제안한 코드를 그대로 사용하기보다, 한 줄씩 직접 타이핑하며 자신의 스타일로 변형해보세요"와 같은 실천 가능한 조언을 제공합니다.

이 보고서를 통해, 교수는 학생의 질문에 "시스템이 그렇게 채점했어"라는 막연한 답변 대신, 데이터라는 객관적인 근거를 바탕으로 학생의 강점과 약점을 함께 이야기하는 건설적인 '코칭'의 시간을 가질 수 있습니다.

### **7. 시작하기: 시스템 설치 및 운영 가이드**

이 강력한 평가 시스템을 실제 현장에서 운영하는 방법은 사용자의 역할에 따라 나뉩니다.

#### **교수/조교 (일상적 사용자)를 위한 안내**
시스템 운영은 매우 간단합니다. 다음의 폴더 구조만 준비되면 됩니다.
```
project-root/
├── student_submission/  # 여기에 모든 학생 폴더를 넣습니다.
├── tools/               # 여기에 모든 분석 도구와 키 파일을 넣습니다.
└── work/                # 이 폴더에서 모든 명령을 실행합니다.
```
1.  **준비:** `tools` 폴더에 제공된 분석 도구들과 암호 해독용 개인키(`private_key.pem`)가 있는지, `student_submission` 폴더에 학생들의 제출물이 모두 들어있는지 확인합니다.
2.  **설치 (최초 1회):** `work` 폴더에서 터미널을 열고 `poetry install`을 입력합니다.
3.  **실행:** 동일한 터미널에서 `poetry run orchestrate --duration <시험시간(분)>`을 입력하면, 커피 한 잔을 마시고 오는 동안 모든 평가가 자동으로 완료됩니다.
4.  **확인:** 실행이 끝나면 `work/output/` 폴더에 생성된 종합 성적표(`evaluation_report.csv`)와 학생별 상세 보고서(HTML 파일들)를 확인합니다.

#### **기술 관리자/개발자 (전문 사용자)를 위한 안내**
-   **환경 설정의 유연성:** 모든 도구의 경로나 파일명은 `work/config.json` 파일에서 쉽게 변경할 수 있습니다. 코드 수정 없이 프로젝트 구조를 유연하게 관리할 수 있습니다.
-   **시스템 확장성:** `Inspector` 시스템은 새로운 분석 모델을 쉽게 추가할 수 있도록 설계되었습니다. 미래에 더 발전된 평가 기법이 나오면, 간단한 코드 추가만으로 시스템을 계속해서 업그레이드할 수 있습니다.

### **8. 결론: 평가는 '심판'이 아닌 '코칭'이 되어야 합니다**

생성형 AI의 시대는 우리에게 위기이자 기회를 동시에 선물했습니다. AI는 인간 개발자의 훌륭한 파트너가 될 수 있지만, 그 과정에서 우리는 인간 고유의 학습 능력과 창의적 문제 해결 과정을 지키고 발전시켜야 할 책무를 안게 되었습니다.

본 프레임워크는 이러한 시대적 과제에 대한 구체적인 응답입니다. **상황 인식(패턴 분류), 집단 지성(동적 앙상블), 그리고 완전한 투명성(해석 가능한 리포팅)**이라는 세 가지 원칙을 통해 기술적 정확성과 교육적 공정성을 동시에 달성하고자 했습니다.

이 시스템을 통해 우리는 평가의 패러다임을 차가운 '심판'에서 따뜻한 '코칭'으로 전환하고자 합니다. 학생에게는 자신의 노력을 정당하게 인정받는 신뢰를, 교수에게는 학생의 성장을 이끄는 통찰력을 제공하는 든든한 동반자가 될 것입니다. AI와 인간이 서로의 가치를 존중하며 함께 성장하는 건강한 개발 생태계를 만드는 데, 이 여정이 의미 있는 발걸음이 되기를 바랍니다.

---

### **9. 부록: 관련 프로젝트 GitHub 저장소**

더 깊이 있는 정보나 직접적인 소스 코드 확인을 원하시는 분들을 위해 관련 프로젝트의 GitHub 저장소 주소를 안내합니다.
-   **[mission-python]**: 학생들의 개발 과정을 자동으로 추적하고 암호화하는 Python 기반 시험 환경입니다.
-   **[Orchestrator]**: 복호화, 복원, 분석 등 전체 평가 파이프라인을 자동화하는 지휘자(Orchestrator)입니다.
-   **[mission-decoder]**: 암호화된 로그와 시스템 서명 파일을 복호화하는 유틸리티입니다.
-   **[mission-restore]**: 복호화된 개발 로그로부터 최종 소스 코드를 재구성하는 유틸리티입니다.
-   **[duplicate_finder]**: 제출된 파일들 간의 내용 기반 중복을 탐지하는 고성능 유틸리티입니다.
-   **[Inspector]**: 동적 앙상블 기법을 사용하여 개발 과정을 심층 분석하고 평가하는 핵심 분석 엔진입니다.

[mission-python]: https://github.com/drsungwon/mission-python
[Orchestrator]: https://github.com/drsungwon/orchestrator
[mission-decoder]: https://github.com/drsungwon/mission-decoder
[mission-restore]: https://github.com/drsungwon/mission-restore
[duplicate_finder]: https://github.com/drsungwon/duplicate_finder
[Inspector]: https://github.com/drsungwon/inspector

### **10. 참고문헌**
 OpenAI, "GPT-4 Technical Report," *arXiv preprint arXiv:2303.08774*, 2023.
 P. Denny, V. Kumar, and N. Giacaman, "Conversing with Copilot: Exploring Prompt Engineering for Solving CS1 Problems Using Natural Language," in *Proc. of the 54th ACM Technical Symposium on Computer Science Education (SIGCSE)*, 2023, pp. 1136-1142.
 A. Gitinabard, Y. Xu, et al., "How widely can analytical models predict student behavior? An analysis of the generalizability of process-based models," in *Proc. of the 9th International Conference on Learning Analytics & Knowledge (LAK)*, 2019, pp. 528-537.
 T. W. Price, Y. Dong, and T. Barnes, "Generating data-driven hints for open-ended programming," in *Proc. of the 9th International Conference on Educational Data Mining (EDM)*, 2016, pp. 191-198.
 P. Blikstein, "Using learning analytics to assess students’ behavior in open-ended programming tasks," in *Proc. of the 1st International Conference on Learning Analytics and Knowledge (LAK)*, 2011, pp. 110-116.